"""
Script 1: extract_to_staging_db.py
SystÃ¨me d'Extraction Intelligent : Rapports Non StructurÃ©s -> Tables de Staging SQL
Version Groq API
"""

import os
import re
import json
import mysql.connector
from pathlib import Path
from typing import Dict, List, Optional
from groq import Groq
from dotenv import load_dotenv
import uuid

# Imports pour la lecture de diffÃ©rents formats de fichiers
PDF_LIB = None
PDF_AVAILABLE = False
try:
    import PyPDF2
    PDF_LIB = PyPDF2
    PDF_AVAILABLE = True
except ImportError:
    try:
        import pypdf
        PDF_LIB = pypdf
        PDF_AVAILABLE = True
    except ImportError:
        PDF_AVAILABLE = False
        print("âš ï¸  Attention: PyPDF2/pypdf non installÃ©. Support PDF dÃ©sactivÃ©.")

DOCX_AVAILABLE = False
DOCX_Document = None
try:
    from docx import Document
    DOCX_Document = Document
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    print("âš ï¸  Attention: python-docx non installÃ©. Support DOCX dÃ©sactivÃ©.")

# --- Configuration Globale ---
load_dotenv()
GROQ_API_KEY = os.getenv("API_KEY")  # Utilise API_KEY depuis .env
DB_CONFIG = {
    'host': os.getenv("DB_HOST"), 
    'user': os.getenv("DB_USER"),
    'password': os.getenv("DB_PASS"), 
    'database': os.getenv("DB_NAME"),
    'charset': 'utf8mb4'
}
# Utiliser les rapports gÃ©nÃ©rÃ©s par structure_to_pdf_text.py
# Support multiple formats: txt, pdf, docx
REPORTS_FOLDER = Path("moroccan_unstructured_data")
SUPPORTED_EXTENSIONS = ['.txt', '.pdf', '.docx', '.doc']


def extract_text_from_pdf(file_path: Path) -> Optional[str]:
    """Extrait le texte d'un fichier PDF"""
    if not PDF_AVAILABLE or PDF_LIB is None:
        print(f"  âš ï¸  Support PDF non disponible. Installez PyPDF2: pip install PyPDF2")
        return None
    
    try:
        text_parts = []
        with open(file_path, 'rb') as file:
            pdf_reader = PDF_LIB.PdfReader(file)
            for page in pdf_reader.pages:
                text_parts.append(page.extract_text())
        
        return '\n'.join(text_parts)
    except Exception as e:
        print(f"  âŒ Erreur lors de l'extraction PDF: {e}")
        return None


def extract_text_from_docx(file_path: Path) -> Optional[str]:
    """Extrait le texte d'un fichier DOCX"""
    if not DOCX_AVAILABLE or DOCX_Document is None:
        print(f"  âš ï¸  Support DOCX non disponible. Installez python-docx: pip install python-docx")
        return None
    
    try:
        doc = DOCX_Document(file_path)
        text_parts = []
        for paragraph in doc.paragraphs:
            text_parts.append(paragraph.text)
        return '\n'.join(text_parts)
    except Exception as e:
        print(f"  âŒ Erreur lors de l'extraction DOCX: {e}")
        return None


def extract_text_from_file(file_path: Path) -> Optional[str]:
    """Extrait le texte d'un fichier selon son extension"""
    extension = file_path.suffix.lower()
    
    if extension == '.txt':
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            print(f"  âŒ Erreur lors de la lecture TXT: {e}")
            return None
    elif extension == '.pdf':
        return extract_text_from_pdf(file_path)
    elif extension in ['.docx', '.doc']:
        return extract_text_from_docx(file_path)
    else:
        print(f"  âš ï¸  Format non supportÃ©: {extension}")
        return None


def extract_patient_metadata_from_text(report_text: str) -> Dict:
    marker = "METADONNEES_PATIENT_JSON:"
    idx = report_text.find(marker)
    if idx == -1:
        return {}
    start = idx + len(marker)
    length = len(report_text)
    while start < length and report_text[start] in " \n\r\t":
        start += 1
    if start >= length or report_text[start] != '{':
        return {}
    depth = 0
    end = start
    for i in range(start, length):
        ch = report_text[i]
        if ch == '{':
            depth += 1
        elif ch == '}':
            depth -= 1
            if depth == 0:
                end = i + 1
                break
    if depth != 0:
        return {}
    json_block = report_text[start:end]
    try:
        # Nettoyer NaN, Infinity, etc. avant le parsing
        json_block = re.sub(r'\bNaN\b', 'null', json_block)
        json_block = re.sub(r'\bInfinity\b', 'null', json_block)
        json_block = re.sub(r'\b-infinity\b', 'null', json_block, flags=re.IGNORECASE)
        metadata = json.loads(json_block)
        if isinstance(metadata, dict):
            return metadata
    except json.JSONDecodeError:
        return {}
    return {}


class StagingExtractor:
    """Extrait les donnÃ©es et les charge dans les tables de staging"""
    
    def __init__(self, api_key: str, reports_folder: Path, db_config: dict):
        self.reports_folder = reports_folder
        
        # Configuration de Groq
        self.client = Groq(api_key=api_key)
        # Utilise llama-3.1-8b-instant : rapide, performant et Ã©conomique
        self.model_name = "llama-3.1-8b-instant"
        
        try:
            self.db_conn = mysql.connector.connect(**db_config)
            self.db_cursor = self.db_conn.cursor(dictionary=True)
            print("\n" + "="*70)
            print("âœ… CONNEXION Ã€ LA BASE DE DONNÃ‰ES RÃ‰USSIE")
            print("="*70)
            
            # VÃ‰RIFICATION: Tester la connexion avec une requÃªte simple
            self.db_cursor.execute("SELECT DATABASE() as db_name, CONNECTION_ID() as conn_id, USER() as user")
            conn_info = self.db_cursor.fetchone()
            print(f"ðŸ“Š Base de donnÃ©es: {conn_info.get('db_name', 'N/A')}")
            print(f"ðŸ”Œ ID Connexion: {conn_info.get('conn_id', 'N/A')}")
            print(f"ðŸ‘¤ Utilisateur: {conn_info.get('user', 'N/A')}")
            
            # VÃ©rifier que les tables existent
            print("\nðŸ” Recherche des tables de staging...")
            self.db_cursor.execute("SHOW TABLES LIKE 'staging_%'")
            tables = [row[list(row.keys())[0]] for row in self.db_cursor.fetchall()]
            
            if tables:
                print(f"âœ… {len(tables)} table(s) de staging trouvÃ©e(s):")
                for i, table in enumerate(tables, 1):
                    # VÃ©rifier le nombre de lignes dans chaque table
                    try:
                        self.db_cursor.execute(f"SELECT COUNT(*) as count FROM {table}")
                        count = self.db_cursor.fetchone()['count']
                        print(f"   {i}. {table} ({count} ligne(s))")
                    except:
                        print(f"   {i}. {table}")
                print("="*70 + "\n")
            else:
                print("âš ï¸  ATTENTION: Aucune table staging_* trouvÃ©e!")
                print("   VÃ©rifiez que le schÃ©ma SQL a Ã©tÃ© exÃ©cutÃ© correctement.")
                print("="*70 + "\n")
                
        except mysql.connector.Error as err:
            print("\n" + "="*70)
            print("âŒ ERREUR DE CONNEXION Ã€ LA BASE DE DONNÃ‰ES")
            print("="*70)
            print(f"Erreur: {err}")
            print("VÃ©rifiez vos paramÃ¨tres de connexion dans le fichier .env")
            print("="*70 + "\n")
            exit()
            
        print(f"âœ“ Dossier des rapports : {self.reports_folder}")
        print(f"âœ“ Formats supportÃ©s : {', '.join(SUPPORTED_EXTENSIONS)}")
    
    def extract_with_llm(self, report_text: str, extraction_type: str) -> Dict:
        """Utilise Groq AI pour extraire les donnÃ©es structurÃ©es du rapport"""
        
        # Prompts optimisÃ©s pour Groq
#         prompts = {
#             'patient_info': """Extrait les informations du patient du rapport mÃ©dical. 
# Retourne UNIQUEMENT un objet JSON valide avec ces champs:
# {"id", "first_name", "last_name", "birthdate": "YYYY-MM-DD", "gender": "M ou F", "ssn", "address", "city", "state", "zip", "race", "ethnicity"}
# Ne retourne que le JSON, sans texte supplÃ©mentaire.""",
            
#             'encounter': """Extrait les informations de la consultation du rapport mÃ©dical.
# Retourne UNIQUEMENT un objet JSON valide avec ces champs:
# {"id", "start_datetime": "YYYY-MM-DD HH:MM:SS", "stop_datetime", "patient_id", "organization_id", "provider_id", "encounter_class", "code", "description", "base_encounter_cost", "total_claim_cost", "payer_coverage", "reason_description"}
# Ne retourne que le JSON, sans texte supplÃ©mentaire.""",
            
#             'conditions': """Extrait TOUTES les pathologies/diagnostics du rapport mÃ©dical.
# Retourne UNIQUEMENT un array JSON valide:
# [{"patient_id", "encounter_id", "start_date": "YYYY-MM-DD", "stop_date", "code", "description"}, ...]
# Ne retourne que le JSON, sans texte supplÃ©mentaire.""",
            
#             'medications': """Extrait TOUTES les prescriptions mÃ©dicamenteuses du rapport mÃ©dical.
# Retourne UNIQUEMENT un array JSON valide:
# [{"patient_id", "encounter_id", "start_datetime", "stop_datetime", "code", "description", "base_cost", "total_cost", "payer_coverage", "reason_description"}, ...]
# Ne retourne que le JSON, sans texte supplÃ©mentaire.""",
            
#             'observations': """Extrait TOUTES les observations/mesures vitales du rapport mÃ©dical.
# Retourne UNIQUEMENT un array JSON valide:
# [{"patient_id", "encounter_id", "date_recorded", "code", "description", "value", "units", "type"}, ...]
# Ne retourne que le JSON, sans texte supplÃ©mentaire.""",
            
#             'allergies': """Extrait TOUTES les allergies du rapport mÃ©dical.
# Retourne UNIQUEMENT un array JSON valide:
# [{"patient_id", "encounter_id", "start_date", "stop_date", "code", "description"}, ...]
# Ne retourne que le JSON, sans texte supplÃ©mentaire.""",
            
#             'procedures': """Extrait TOUS les actes mÃ©dicaux/interventions du rapport mÃ©dical.
# Retourne UNIQUEMENT un array JSON valide:
# [{"patient_id", "encounter_id", "date_performed", "code", "description", "base_cost", "reason_description"}, ...]
# Ne retourne que le JSON, sans texte supplÃ©mentaire.""",
            
#             'immunizations': """Extrait TOUTES les vaccinations du rapport mÃ©dical.
# Retourne UNIQUEMENT un array JSON valide:
# [{"patient_id", "encounter_id", "date_administered", "code", "description", "base_cost"}, ...]
# Ne retourne que le JSON, sans texte supplÃ©mentaire."""
#         }

        prompts = {
    'patient_info': """Extrait les informations du patient du rapport mÃ©dical. 
Retourne UNIQUEMENT un objet JSON valide avec ces champs:
{"id", "first_name", "last_name", "birthdate": "YYYY-MM-DD", "gender": "M ou F", "ssn", "address", "city", "state", "zip", "race", "ethnicity"}
Ne retourne que le JSON, sans texte supplÃ©mentaire.""",
    
    'encounter': """Extrait les informations de la consultation du rapport mÃ©dical.
Retourne UNIQUEMENT un objet JSON valide avec ces champs:
{"id", "start_datetime": "YYYY-MM-DD HH:MM:SS", "stop_datetime": "YYYY-MM-DD HH:MM:SS", "patient_id", "organization_id", "provider_id", "encounter_class", "code", "description", "base_encounter_cost", "total_claim_cost", "payer_coverage", "reason_description"}
Ne retourne que le JSON, sans texte supplÃ©mentaire.""",
    
    'conditions': """Extrait TOUTES les pathologies/diagnostics du rapport mÃ©dical.
Retourne UNIQUEMENT un array JSON valide:
[{"start_date": "YYYY-MM-DD", "stop_date": "YYYY-MM-DD", "code", "description"}, ...]
Ne retourne que le JSON, sans texte supplÃ©mentaire. NE PAS INCLURE patient_id ou encounter_id.""",
    
    'medications': """Extrait TOUTES les prescriptions mÃ©dicamenteuses du rapport mÃ©dical.
Retourne UNIQUEMENT un array JSON valide:
[{"start_datetime": "YYYY-MM-DD HH:MM:SS", "stop_datetime": "YYYY-MM-DD HH:MM:SS", "code", "description", "base_cost", "total_cost", "payer_coverage", "reason_description"}, ...]
Ne retourne que le JSON, sans texte supplÃ©mentaire. NE PAS INCLURE patient_id ou encounter_id.""",
    
    'observations': """Extrait TOUTES les observations/mesures vitales du rapport mÃ©dical.
Retourne UNIQUEMENT un array JSON valide:
[{"date_recorded": "YYYY-MM-DD HH:MM:SS", "code", "description", "value", "units", "type"}, ...]
Ne retourne que le JSON, sans texte supplÃ©mentaire. NE PAS INCLURE patient_id ou encounter_id.""",
    
    'allergies': """Extrait TOUTES les allergies du rapport mÃ©dical.
Retourne UNIQUEMENT un array JSON valide:
[{"start_date": "YYYY-MM-DD", "stop_date": "YYYY-MM-DD", "code", "description"}, ...]
Ne retourne que le JSON, sans texte supplÃ©mentaire. NE PAS INCLURE patient_id ou encounter_id.""",
    
    'procedures': """Extrait TOUS les actes mÃ©dicaux/interventions du rapport mÃ©dical.
Retourne UNIQUEMENT un array JSON valide:
[{"date_performed": "YYYY-MM-DD HH:MM:SS", "code", "description", "base_cost", "reason_description"}, ...]
Ne retourne que le JSON, sans texte supplÃ©mentaire. NE PAS INCLURE patient_id ou encounter_id.""",
    
    'immunizations': """Extrait TOUTES les vaccinations du rapport mÃ©dical.
Retourne UNIQUEMENT un array JSON valide:
[{"date_administered": "YYYY-MM-DD HH:MM:SS", "code", "description", "base_cost"}, ...]
Ne retourne que le JSON, sans texte supplÃ©mentaire. NE PAS INCLURE patient_id ou encounter_id."""
}
        
        prompt = prompts.get(extraction_type)
        if not prompt: 
            return {}

        try:
            # Appel Ã  Groq
            full_prompt = f"{prompt}\n\nRAPPORT MÃ‰DICAL:\n{report_text[:12000]}"
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "Tu es un assistant expert en extraction de donnÃ©es mÃ©dicales. Tu retournes uniquement du JSON valide."},
                    {"role": "user", "content": full_prompt}
                ],
                temperature=0.1,  # Basse tempÃ©rature pour plus de cohÃ©rence
                max_tokens=4000
            )
            
            # Extraction du JSON
            content = response.choices[0].message.content
            
            # Nettoyage du markdown si prÃ©sent
            content = re.sub(r'```json\s*', '', content)
            content = re.sub(r'```\s*', '', content)
            content = content.strip()
            
            # Extraction du JSON
            json_match = re.search(r'\{.*\}|\[.*\]', content, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                # Nettoyer NaN, Infinity, etc. avant le parsing
                json_str = re.sub(r'\bNaN\b', 'null', json_str)
                json_str = re.sub(r'\bInfinity\b', 'null', json_str)
                json_str = re.sub(r'\b-infinity\b', 'null', json_str, flags=re.IGNORECASE)
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError as e:
                    print(f"  âš ï¸  Erreur parsing JSON pour {extraction_type}: {e}")
                    return {} if extraction_type in ['patient_info', 'encounter'] else []
            
            print(f"  âš ï¸  Aucun JSON valide retournÃ© par Groq pour {extraction_type}")
            return {}
                
        except Exception as e:
            print(f"âœ— Erreur extraction Groq ({extraction_type}): {e}")
            return {} if extraction_type in ['patient_info', 'encounter'] else []
    
    def clean_value(self, value):
        """Nettoie une valeur pour l'insertion en base de donnÃ©es"""
        import math
        
        # Si None, retourner None
        if value is None:
            return None
        
        # Si c'est un float NaN
        if isinstance(value, float) and math.isnan(value):
            return None
        
        # Si c'est une chaÃ®ne reprÃ©sentant NaN
        if isinstance(value, str):
            value_lower = value.lower().strip()
            if value_lower in ['nan', 'none', 'null', '', 'undefined']:
                return None
        
        # Si c'est un nombre infini
        if isinstance(value, float) and (math.isinf(value) or math.isnan(value)):
            return None
        
        return value
    
    def validate_data(self, data: Dict, table_name: str) -> Dict:
        """Valide et nettoie les donnÃ©es avant insertion selon le schÃ©ma exact"""
        if not isinstance(data, dict):
            print(f"  [DEBUG] validate_data: data n'est pas un dictionnaire")
            return {}
        
        # RÃ©cupÃ©rer les colonnes valides de la table
        valid_cols = self.get_table_columns(table_name)
        
        if not valid_cols:
            print(f"  âŒ ERREUR: Impossible de rÃ©cupÃ©rer les colonnes de {table_name}")
            return {}
        
        # Filtrer et nettoyer les valeurs selon les colonnes rÃ©elles
        item_filtered = {}
        skipped_cols = []
        
        for k, v in data.items():
            # S'assurer que la clÃ© est valide et n'est pas NaN
            if k in valid_cols and not (isinstance(k, str) and k.lower() == 'nan'):
                # Nettoyer la valeur
                cleaned_value = self.clean_value(v)
                # Ne pas inclure les clÃ©s avec des valeurs invalides comme nom de colonne
                item_filtered[k] = cleaned_value
            else:
                if k not in valid_cols:
                    skipped_cols.append(f"{k} (colonne inexistante)")
                elif isinstance(k, str) and k.lower() == 'nan':
                    skipped_cols.append(f"{k} (clÃ© NaN)")
        
        if skipped_cols and table_name == 'staging_patients':
            print(f"  [DEBUG] Colonnes ignorÃ©es: {', '.join(skipped_cols[:5])}")
        
        if not item_filtered:
            print(f"  âŒ ERREUR: Aucune colonne valide aprÃ¨s filtrage pour {table_name}")
            print(f"     [DEBUG] Colonnes reÃ§ues: {list(data.keys())}")
            print(f"     [DEBUG] Colonnes valides dans la table: {sorted(list(valid_cols))[:10]}")
        
        return item_filtered
    
    def get_primary_key(self, table_name: str) -> str:
        """DÃ©tecte automatiquement la clÃ© primaire d'une table selon le schÃ©ma"""
        # Selon le schÃ©ma SQL :
        # - staging_patients et staging_encounters : utilisent 'id' (TEXT avec UNIQUE KEY)
        # - Toutes les autres tables : utilisent 'staging_id' (INT AUTO_INCREMENT PRIMARY KEY)
        if table_name in ['staging_patients', 'staging_encounters']:
            return 'id'
        else:
            return 'staging_id'
    
    def get_table_columns(self, table_name: str) -> set:
        """RÃ©cupÃ¨re la liste des colonnes valides d'une table"""
        try:
            self.db_cursor.execute(f"DESCRIBE {table_name}")
            return {row['Field'] for row in self.db_cursor.fetchall()}
        except Exception as e:
            print(f"  âš ï¸  Erreur lors de la rÃ©cupÃ©ration des colonnes de {table_name}: {e}")
            return set()
    
    def verify_insertion(self, table_name: str, primary_key: str, primary_value: str) -> bool:
        """VÃ©rifie qu'un enregistrement a bien Ã©tÃ© insÃ©rÃ© en faisant un SELECT"""
        try:
            # Construire la requÃªte SELECT
            select_sql = f"SELECT * FROM {table_name} WHERE {primary_key} = %s LIMIT 1"
            self.db_cursor.execute(select_sql, (primary_value,))
            result = self.db_cursor.fetchone()
            
            if result:
                # Afficher quelques informations clÃ©s pour confirmation
                if table_name == 'staging_patients':
                    print(f"      âœ“ VÃ©rifiÃ©: Patient {result.get('first_name', '')} {result.get('last_name', '')} (ID: {primary_value})")
                elif table_name == 'staging_encounters':
                    print(f"      âœ“ VÃ©rifiÃ©: Consultation {result.get('id', 'N/A')} pour patient {result.get('patient_id', 'N/A')}")
                else:
                    # Pour les tables enfants, afficher le staging_id et quelques infos
                    staging_id = result.get('staging_id', primary_value)
                    desc = result.get('description', '')[:50] if result.get('description') else 'N/A'
                    print(f"      âœ“ VÃ©rifiÃ©: {table_name} - staging_id: {staging_id} ({desc}...)")
                return True
            else:
                print(f"      âš ï¸  ATTENTION: L'enregistrement n'a pas Ã©tÃ© trouvÃ© aprÃ¨s insertion!")
                return False
        except Exception as e:
            print(f"      âš ï¸  Erreur lors de la vÃ©rification: {e}")
            return False
    
    def insert_single_record(self, table_name: str, data: Dict, report_filename: str) -> bool:
        """InsÃ¨re UNE seule donnÃ©e avec validation, commit immÃ©diat et vÃ©rification"""
        if not data:
            return False
        
        # Ajouter le nom du fichier source
        data['report_filename'] = report_filename
        
        # Valider et nettoyer les donnÃ©es
        item_filtered = self.validate_data(data, table_name)
        
        if not item_filtered:
            print(f"  âŒ ERREUR: Aucune donnÃ©e valide pour {table_name}")
            print(f"     [DEBUG] DonnÃ©es reÃ§ues: {list(data.keys()) if data else 'AUCUNE'}")
            print(f"     [DEBUG] Colonnes filtrÃ©es: {len(item_filtered)} colonne(s)")
            return False
        
        cols = ', '.join(item_filtered.keys())
        placeholders = ', '.join(['%s'] * len(item_filtered))
        sql = f"INSERT INTO {table_name} ({cols}) VALUES ({placeholders})"
        
        # DÃ©tecter la clÃ© primaire de la table
        primary_key = self.get_primary_key(table_name)
        
        try:
            # Afficher le nom de la table avant insertion
            print(f"      ðŸ“‹ TABLE: {table_name}")
            
            # Compter les lignes AVANT insertion
            self.db_cursor.execute(f"SELECT COUNT(*) as count_before FROM {table_name}")
            count_before = self.db_cursor.fetchone()['count_before']
            
            # INSERT
            self.db_cursor.execute(sql, list(item_filtered.values()))
            rows_affected = self.db_cursor.rowcount
            
            # VÃ‰RIFICATION: RÃ©cupÃ©rer la clÃ© primaire AVANT le commit
            primary_value = None
            
            if primary_key == 'staging_id':
                # Pour les tables avec staging_id AUTO_INCREMENT, rÃ©cupÃ©rer le dernier ID insÃ©rÃ©
                self.db_cursor.execute("SELECT LAST_INSERT_ID() as last_id")
                result = self.db_cursor.fetchone()
                if result and result['last_id']:
                    primary_value = result['last_id']
            else:
                # Pour staging_patients et staging_encounters, utiliser l'ID du dictionnaire
                primary_value = item_filtered.get('id')
            
            # Commit aprÃ¨s avoir rÃ©cupÃ©rÃ© l'ID
            self.db_conn.commit()  # Commit immÃ©diat aprÃ¨s chaque insertion
            
            # Compter les lignes APRÃˆS insertion
            self.db_cursor.execute(f"SELECT COUNT(*) as count_after FROM {table_name}")
            count_after = self.db_cursor.fetchone()['count_after']
            rows_inserted = count_after - count_before
            
            # AFFICHAGE DE LA RÃ‰USSITE avec nom de table
            if rows_inserted > 0:
                print(f"      âœ… INSERTION RÃ‰USSIE dans la table: {table_name}")
                print(f"         â†’ Lignes avant: {count_before} | AprÃ¨s: {count_after} | AjoutÃ©es: +{rows_inserted}")
                print(f"         â†’ Lignes affectÃ©es par INSERT: {rows_affected}")
                if primary_value:
                    print(f"         â†’ ClÃ© primaire: {primary_key} = {primary_value}")
            else:
                print(f"      âš ï¸  INSERTION: Aucune nouvelle ligne ajoutÃ©e dans la table: {table_name}")
                print(f"         â†’ Lignes avant: {count_before} | AprÃ¨s: {count_after}")
            
            # VÃ©rification avec SELECT pour confirmer
            if primary_value:
                verified = self.verify_insertion(table_name, primary_key, str(primary_value))
                if verified:
                    print(f"      âœ… VÃ‰RIFICATION: Enregistrement confirmÃ© dans la base de donnÃ©es")
            else:
                # Si pas d'ID, vÃ©rifier avec le nom du fichier
                if primary_key == 'staging_id':
                    select_sql = f"SELECT * FROM {table_name} WHERE report_filename = %s ORDER BY staging_id DESC LIMIT 1"
                else:
                    select_sql = f"SELECT * FROM {table_name} WHERE report_filename = %s ORDER BY {primary_key} DESC LIMIT 1"
                
                self.db_cursor.execute(select_sql, (report_filename,))
                result = self.db_cursor.fetchone()
                if result:
                    pk_val = result.get(primary_key, 'N/A')
                    print(f"      âœ… VÃ‰RIFICATION: Dernier enregistrement trouvÃ© ({primary_key}: {pk_val})")
                else:
                    print(f"      âš ï¸  VÃ‰RIFICATION: Aucun enregistrement trouvÃ© pour {report_filename}")
            
            return True
        except mysql.connector.Error as err:
            self.db_conn.rollback()  # Rollback en cas d'erreur
            if err.errno == 1062:  # ClÃ© dupliquÃ©e
                print(f"  âš ï¸  Doublon ignorÃ© pour {table_name}: {data.get('id', 'N/A')}")
                print(f"     [INFO] L'enregistrement existe dÃ©jÃ  dans la base de donnÃ©es")
            else:
                print(f"  âŒ ERREUR insertion dans {table_name}: {err}")
                print(f"     [DEBUG] Code erreur: {err.errno}")
                print(f"     [DEBUG] Message: {err.msg}")
                print(f"     [DEBUG] Colonnes tentÃ©es: {list(item_filtered.keys())}")
                print(f"     [DEBUG] Nombre de valeurs: {len(item_filtered)}")
                if item_filtered:
                    print(f"     [DEBUG] Exemple de valeur: {list(item_filtered.items())[:3]}")
            return False
    
    def insert_staging_data(self, table_name: str, data: Dict | List[Dict], report_filename: str) -> int:
        """InsÃ¨re les donnÃ©es extraites une par une avec validation"""
        if not data: 
            return 0
        data_list = data if isinstance(data, list) else [data]
        
        count = 0
        for idx, item in enumerate(data_list, 1):
            if not isinstance(item, dict): 
                print(f"  âš ï¸  Item {idx} ignorÃ© (n'est pas un dictionnaire)")
                continue
            
            if self.insert_single_record(table_name, item, report_filename):
                count += 1
                if len(data_list) > 1:
                    print(f"    âœ“ {table_name} #{idx}/{len(data_list)} insÃ©rÃ©")
        
        return count

    def process_report(self, report_path: Path) -> Dict[str, int]:
        """Traite un rapport complet : extraction â†’ validation â†’ insertion immÃ©diate"""
        print(f"\nðŸ“„ Traitement : {report_path.name} ({report_path.suffix})")
        
        # Extraire le texte selon le format du fichier
        report_text = extract_text_from_file(report_path)
        if not report_text:
            print(f"  âœ— Impossible d'extraire le texte du fichier")
            return {}
        
        if len(report_text.strip()) == 0:
            print(f"  âš ï¸  Fichier vide ou aucun texte extrait")
            return {}
        
        stats = {}

        # ========== Ã‰TAPE 1: PATIENT ==========
        print("  ðŸ” [1/8] Extraction des donnÃ©es patient...")
        patient_metadata = extract_patient_metadata_from_text(report_text)
        patient_data = patient_metadata.copy() if patient_metadata else {}

        # Si pas de mÃ©tadonnÃ©es valides, utiliser l'IA
        if not patient_data:
            print("    â†’ Utilisation de Groq pour extraire les donnÃ©es patient...")
            patient_data = self.extract_with_llm(report_text, 'patient_info') or {}

        # Toujours gÃ©nÃ©rer un ID unique si manquant
        if not patient_data.get('id'):
            patient_data['id'] = str(uuid.uuid4())

        # Assurer la cohÃ©rence minimale
        for key in ["first_name", "last_name", "birthdate", "gender"]:
            patient_data.setdefault(key, None)

        # Validation et insertion immÃ©diate du patient
        if patient_data:
            print(f"    â†’ Insertion dans la table: staging_patients")
            print(f"    [DEBUG] DonnÃ©es patient avant insertion: {list(patient_data.keys())}")
            print(f"    [DEBUG] ID patient: {patient_data.get('id', 'MANQUANT')}")
            print(f"    [DEBUG] Nom: {patient_data.get('first_name', 'N/A')} {patient_data.get('last_name', 'N/A')}")
            
            stats['patients'] = self.insert_staging_data(
                'staging_patients', patient_data, report_path.name
            )
            
            if stats['patients'] > 0:
                print(f"    âœ… Patient insÃ©rÃ© avec succÃ¨s (ID: {patient_data['id']})")
            else:
                print("    âŒ Ã‰CHEC insertion patient - ArrÃªt du traitement")
                print("    [DEBUG] VÃ©rifiez les logs ci-dessus pour voir la cause de l'Ã©chec")
                return stats
        else:
            print("    âŒ Aucune donnÃ©e patient extraite - ArrÃªt du traitement")
            print("    [DEBUG] VÃ©rifiez que le rapport contient des mÃ©tadonnÃ©es ou que Groq a extrait les donnÃ©es")
            return stats

        # ========== Ã‰TAPE 2: ENCOUNTER ==========
        print("  ðŸ” [2/8] Extraction des donnÃ©es consultation...")
        encounter_data = self.extract_with_llm(report_text, 'encounter') or {}

        if not encounter_data.get('id'):
            encounter_data['id'] = str(uuid.uuid4())
        encounter_data['patient_id'] = patient_data['id']

        # ComplÃ©ter valeurs minimales
        encounter_data.setdefault("encounter_class", "wellness")
        encounter_data.setdefault("description", "Consultation de routine")
        encounter_data.setdefault("base_encounter_cost", 591)
        encounter_data.setdefault("total_claim_cost", 591)

        # Validation et insertion immÃ©diate de l'encounter
        if encounter_data:
            print(f"    â†’ Insertion dans la table: staging_encounters")
            stats['encounters'] = self.insert_staging_data(
                'staging_encounters', encounter_data, report_path.name
            )
            if stats['encounters'] > 0:
                print(f"    âœ“ Consultation insÃ©rÃ©e (ID: {encounter_data['id']})")
            else:
                print("    âš ï¸  Ã‰chec insertion consultation")
        else:
            print("    âš ï¸  Aucune donnÃ©e consultation extraite")

        # ========== Ã‰TAPES 3-8: TABLES ENFANTS (une par une) ==========
        child_tables = [
            ('conditions', 'staging_conditions'),
            ('medications', 'staging_medications'),
            ('observations', 'staging_observations'),
            ('allergies', 'staging_allergies'),
            ('procedures', 'staging_procedures'),
            ('immunizations', 'staging_immunizations')
        ]

        for idx, (extraction_type, table_name) in enumerate(child_tables, 3):
            print(f"  ðŸ” [{idx}/8] Extraction {extraction_type}...")
            child_data_list = self.extract_with_llm(report_text, extraction_type)
            
            if not child_data_list or not isinstance(child_data_list, list):
                print(f"    â„¹ï¸  Aucune donnÃ©e {extraction_type} trouvÃ©e")
                stats[extraction_type] = 0
                continue
            
            # Ajouter les IDs de rÃ©fÃ©rence Ã  chaque item
            for item in child_data_list:
                if isinstance(item, dict):
                    item['patient_id'] = patient_data['id']
                    item['encounter_id'] = encounter_data.get('id')
            
            # Insertion une par une avec validation
            print(f"    â†’ Insertion dans la table: {table_name} ({len(child_data_list)} enregistrement(s))")
            stats[extraction_type] = self.insert_staging_data(
                table_name, child_data_list, report_path.name
            )
            if stats[extraction_type] > 0:
                print(f"    âœ“ {stats[extraction_type]}/{len(child_data_list)} {extraction_type} insÃ©rÃ©(s)")

        print(f"  âœ… RÃ©sumÃ©: {stats}")
        return stats

    
    def process_all_reports(self, max_reports: int = None):
        """Traite tous les rapports du dossier (txt, pdf, docx)"""
        # Recherche rÃ©cursive de tous les fichiers supportÃ©s
        report_files = []
        for ext in SUPPORTED_EXTENSIONS:
            found_files = list(self.reports_folder.rglob(f"*{ext}"))
            report_files.extend(found_files)
        
        if not report_files:
            print(f"âœ— Aucun fichier supportÃ© trouvÃ© dans : {self.reports_folder.resolve()}")
            print(f"   Formats recherchÃ©s: {', '.join(SUPPORTED_EXTENSIONS)}")
            return
        
        # Trier par nom pour un traitement ordonnÃ©
        report_files.sort(key=lambda x: x.name)
        
        if max_reports: 
            report_files = report_files[:max_reports]
        
        # Statistiques par format
        format_stats = {}
        for file in report_files:
            ext = file.suffix.lower()
            format_stats[ext] = format_stats.get(ext, 0) + 1
        
        print(f"\n{'='*70}\nTRAITEMENT DE {len(report_files)} RAPPORTS VERS STAGING\n{'='*70}")
        print(f"ðŸ“Š RÃ©partition par format:")
        for ext, count in sorted(format_stats.items()):
            print(f"   {ext}: {count} fichier(s)")
        print(f"{'='*70}")
        
        for idx, report_path in enumerate(report_files, 1):
            print(f"\n[{idx}/{len(report_files)}]")
            try:
                self.process_report(report_path)
            except Exception as e:
                print(f"âœ— Erreur traitement {report_path.name}: {e}")
        print(f"\n{'='*70}\nEXTRACTION VERS STAGING TERMINÃ‰E\n{'='*70}\n")
    
    def close(self):
        self.db_cursor.close()
        self.db_conn.close()
        print("âœ“ Connexion DB (Staging) fermÃ©e")

if __name__ == "__main__":
    if not GROQ_API_KEY:
        print("âœ— ERREUR: API_KEY n'est pas configurÃ©e dans le fichier .env")
        print("Obtenez votre clÃ© API Groq sur: https://console.groq.com/keys")
        exit()
    
    print("ðŸš€ (SCRIPT 1: EXTRACTION avec Groq) ðŸš€")
    extractor = StagingExtractor(
        api_key=GROQ_API_KEY, 
        reports_folder=REPORTS_FOLDER, 
        db_config=DB_CONFIG
    )
    extractor.process_all_reports(max_reports=None)  
    extractor.close()
    print("\nâœ… Extraction terminÃ©e. Lancez 'process_staging_to_production.py'.")